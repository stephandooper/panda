{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sat Jun  6 18:57:30 2020       \r\n",
      "+-----------------------------------------------------------------------------+\r\n",
      "| NVIDIA-SMI 440.64.00    Driver Version: 440.64.00    CUDA Version: 10.2     |\r\n",
      "|-------------------------------+----------------------+----------------------+\r\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\r\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\r\n",
      "|===============================+======================+======================|\r\n",
      "|   0  Tesla M40           On   | 00000000:04:00.0 Off |                    0 |\r\n",
      "| N/A   29C    P8    14W / 250W |      0MiB / 11448MiB |      0%      Default |\r\n",
      "+-------------------------------+----------------------+----------------------+\r\n",
      "|   1  Tesla M40           On   | 00000000:82:00.0 Off |                    0 |\r\n",
      "| N/A   29C    P8    16W / 250W |      0MiB / 11448MiB |      0%      Default |\r\n",
      "+-------------------------------+----------------------+----------------------+\r\n",
      "                                                                               \r\n",
      "+-----------------------------------------------------------------------------+\r\n",
      "| Processes:                                                       GPU Memory |\r\n",
      "|  GPU       PID   Type   Process name                             Usage      |\r\n",
      "|=============================================================================|\r\n",
      "|  No running processes found                                                 |\r\n",
      "+-----------------------------------------------------------------------------+\r\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The tensorboard extension is already loaded. To reload it, use:\n",
      "  %reload_ext tensorboard\n",
      "2.2.0\n",
      "[PhysicalDevice(name='/physical_device:CPU:0', device_type='CPU'), PhysicalDevice(name='/physical_device:XLA_CPU:0', device_type='XLA_CPU'), PhysicalDevice(name='/physical_device:XLA_GPU:0', device_type='XLA_GPU'), PhysicalDevice(name='/physical_device:XLA_GPU:1', device_type='XLA_GPU'), PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU'), PhysicalDevice(name='/physical_device:GPU:1', device_type='GPU')]\n"
     ]
    }
   ],
   "source": [
    "%load_ext tensorboard\n",
    "\n",
    "# load tensorflow dependencies\n",
    "import tensorflow as tf\n",
    "from classification_models.tfkeras import Classifiers\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow_addons.metrics import CohenKappa\n",
    "from tensorflow.keras import layers as KL\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import ReduceLROnPlateau\n",
    "import tensorflow.keras.backend as K\n",
    "import efficientnet.tfkeras as efn\n",
    "\n",
    "# 16 bit precision computing\n",
    "from tensorflow.keras.mixed_precision import experimental as mixed_precision\n",
    "print(tf.__version__)\n",
    "print(tf.config.experimental.list_physical_devices())\n",
    "\n",
    "\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "from pathlib import Path\n",
    "from pprint import pprint\n",
    "import pandas as pd\n",
    "from glob import glob\n",
    "import skimage.io\n",
    "import sys\n",
    "\n",
    "from tensorflow.keras.utils import Progbar\n",
    "\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import cohen_kappa_score, make_scorer\n",
    "import time\n",
    "\n",
    "\n",
    "sys.path.insert(0,'..')\n",
    "from model.layers import GeneralizedMeanPooling2D\n",
    "\n",
    "# custom packages\n",
    "from preprocessing.utils.data_loader import PandasDataLoader\n",
    "from preprocessing.generators import TiffGenerator, TiffFromCoords\n",
    "from utils.utils import set_gpu_memory, seed_all\n",
    "\n",
    "from model.network import Network\n",
    "\n",
    "# Augmentation packages\n",
    "\n",
    "# custom stain augmentation\n",
    "from preprocessing.augmentations import StainAugment\n",
    "\n",
    "import albumentations as A\n",
    "from albumentations import (\n",
    "    Flip, ShiftScaleRotate, RandomRotate90,\n",
    "    ShiftScaleRotate, Blur, OpticalDistortion, RandomBrightnessContrast, \n",
    "    OneOf, Compose, RandomScale, ElasticTransform, GaussNoise, GaussianBlur,\n",
    "    RandomBrightness, RandomContrast\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2 Physical GPUs, 1 Logical GPUs\n",
      "Compute dtype: float16\n",
      "Variable dtype: float32\n"
     ]
    }
   ],
   "source": [
    "seed_all(20)\n",
    "DATA_DIR = Path('../data/')\n",
    "\n",
    "# control for the gpu memory, and number of used gpu's\n",
    "set_gpu_memory(device_type='GPU')\n",
    "# see the utils functions which seeds are set\n",
    "# tensorflow ops still have to be seeded manually...\n",
    "seed_all()\n",
    "\n",
    "policy = mixed_precision.Policy('mixed_float16')\n",
    "mixed_precision.set_policy(policy)\n",
    "\n",
    "print('Compute dtype: %s' % policy.compute_dtype)\n",
    "print('Variable dtype: %s' % policy.variable_dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------------------\n",
    "# Directories\n",
    "# ------------------\n",
    "DATA_DIR = '../data'  # General path to the data dir\n",
    "IMG_DIR = '../data/train_images'  # Path to the TILED images\n",
    "TRAIN_MASKS_DIR = '../data/masks'  # Path to the masks\n",
    "\n",
    "# ------------------\n",
    "# Data constants\n",
    "# ------------------\n",
    "NFOLDS = 4  # number of folds to use for training/validation (cross validation)\n",
    "SEED=5  # the seed TODO: REPLACE THIS WITH A FUNCTION THAT SEEDS EVERYTHING WITH SEED\n",
    "TRAIN_FOLD=0  # select the first fold for training/validation\n",
    "\n",
    "# ------------------\n",
    "# Network parameters\n",
    "# ------------------\n",
    "# some of these parameters might disappear in a future release\n",
    "SZ = 256  # width and heigth of the image\n",
    "NUM_CLASSES = 6 \n",
    "BATCH_SIZE = 5\n",
    "NUM_EPOCHS = 15  \n",
    "NUM_TILES = 16 # this number cannot be changed freely in the png tile generator\n",
    "LEARNING_RATE = 1e-3\n",
    "TILE_LEVEL = 2\n",
    "\n",
    "tile_params = {'N': NUM_TILES, 'sz': SZ}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "possible faulty slide reasons ['marks' 'No Mask' 'Background only'\n",
      " 'No cancerous tissue but ISUP Grade > 0' 'tiss' 'blank']\n",
      "********************\n",
      "The training dataframe shape before filtering:(10616, 4)\n",
      "The skip dataframe has shape: (675, 2), with reasons ['marks', 'No Mask', 'Background only', 'No cancerous tissue but ISUP Grade > 0', 'tiss', 'blank']\n",
      "Filtering based on the following columns: ['marks', 'No Mask', 'Background only', 'No cancerous tissue but ISUP Grade > 0', 'tiss', 'blank']\n",
      "number of duplicates in the skip df: (13, 2)\n",
      "Training dataframe after filtering: (9954, 4)\n",
      "Number of rows removed by filter: 662\n",
      "********************\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image_id</th>\n",
       "      <th>data_provider</th>\n",
       "      <th>isup_grade</th>\n",
       "      <th>gleason_score</th>\n",
       "      <th>split</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0005f7aaab2800f6170c399693a96917</td>\n",
       "      <td>karolinska</td>\n",
       "      <td>0</td>\n",
       "      <td>0+0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>000920ad0b612851f8e01bcc880d9b3d</td>\n",
       "      <td>karolinska</td>\n",
       "      <td>0</td>\n",
       "      <td>0+0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0018ae58b01bdadc8e347995b69f99aa</td>\n",
       "      <td>radboud</td>\n",
       "      <td>4</td>\n",
       "      <td>4+4</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>001c62abd11fa4b57bf7a6c603a11bb9</td>\n",
       "      <td>karolinska</td>\n",
       "      <td>4</td>\n",
       "      <td>4+4</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>001d865e65ef5d2579c190a0e0350d8f</td>\n",
       "      <td>karolinska</td>\n",
       "      <td>0</td>\n",
       "      <td>0+0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10622</th>\n",
       "      <td>ffcd99c47e57ad2934dc6bbf5edf6675</td>\n",
       "      <td>karolinska</td>\n",
       "      <td>0</td>\n",
       "      <td>0+0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10624</th>\n",
       "      <td>ffd2841373b39792ab0c84cccd066e31</td>\n",
       "      <td>radboud</td>\n",
       "      <td>0</td>\n",
       "      <td>negative</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10625</th>\n",
       "      <td>ffdc59cd580a1468eac0e6a32dd1ff2d</td>\n",
       "      <td>radboud</td>\n",
       "      <td>5</td>\n",
       "      <td>4+5</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10626</th>\n",
       "      <td>ffe06afd66a93258f8fabdef6044e181</td>\n",
       "      <td>radboud</td>\n",
       "      <td>0</td>\n",
       "      <td>negative</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10628</th>\n",
       "      <td>ffe9bcababc858e04840669e788065a1</td>\n",
       "      <td>radboud</td>\n",
       "      <td>4</td>\n",
       "      <td>4+4</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7465 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                               image_id data_provider  isup_grade  \\\n",
       "0      0005f7aaab2800f6170c399693a96917    karolinska           0   \n",
       "1      000920ad0b612851f8e01bcc880d9b3d    karolinska           0   \n",
       "2      0018ae58b01bdadc8e347995b69f99aa       radboud           4   \n",
       "3      001c62abd11fa4b57bf7a6c603a11bb9    karolinska           4   \n",
       "4      001d865e65ef5d2579c190a0e0350d8f    karolinska           0   \n",
       "...                                 ...           ...         ...   \n",
       "10622  ffcd99c47e57ad2934dc6bbf5edf6675    karolinska           0   \n",
       "10624  ffd2841373b39792ab0c84cccd066e31       radboud           0   \n",
       "10625  ffdc59cd580a1468eac0e6a32dd1ff2d       radboud           5   \n",
       "10626  ffe06afd66a93258f8fabdef6044e181       radboud           0   \n",
       "10628  ffe9bcababc858e04840669e788065a1       radboud           4   \n",
       "\n",
       "      gleason_score  split  \n",
       "0               0+0      1  \n",
       "1               0+0      3  \n",
       "2               4+4      2  \n",
       "3               4+4      3  \n",
       "4               0+0      1  \n",
       "...             ...    ...  \n",
       "10622           0+0      2  \n",
       "10624      negative      2  \n",
       "10625           4+5      2  \n",
       "10626      negative      3  \n",
       "10628           4+4      1  \n",
       "\n",
       "[7465 rows x 5 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image_id</th>\n",
       "      <th>data_provider</th>\n",
       "      <th>isup_grade</th>\n",
       "      <th>gleason_score</th>\n",
       "      <th>split</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>002a4db09dad406c85505a00fb6f6144</td>\n",
       "      <td>karolinska</td>\n",
       "      <td>0</td>\n",
       "      <td>0+0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>003046e27c8ead3e3db155780dc5498e</td>\n",
       "      <td>karolinska</td>\n",
       "      <td>1</td>\n",
       "      <td>3+3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>00412139e6b04d1e1cee8421f38f6e90</td>\n",
       "      <td>karolinska</td>\n",
       "      <td>0</td>\n",
       "      <td>0+0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>004f6b3a66189b4e88b6a01ba19d7d31</td>\n",
       "      <td>karolinska</td>\n",
       "      <td>1</td>\n",
       "      <td>3+3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>00c15b23b30a5ba061358d9641118904</td>\n",
       "      <td>radboud</td>\n",
       "      <td>5</td>\n",
       "      <td>4+5</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10596</th>\n",
       "      <td>ff339e5fa7be6af83c1b43796092398f</td>\n",
       "      <td>karolinska</td>\n",
       "      <td>4</td>\n",
       "      <td>4+4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10603</th>\n",
       "      <td>ff596d5292ab979e9ba7291d0743b3fb</td>\n",
       "      <td>karolinska</td>\n",
       "      <td>0</td>\n",
       "      <td>0+0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10618</th>\n",
       "      <td>ffc005d56a21efbd034425623f596984</td>\n",
       "      <td>karolinska</td>\n",
       "      <td>2</td>\n",
       "      <td>3+4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10621</th>\n",
       "      <td>ffcbb41626c9267c5c20c4804bd5639a</td>\n",
       "      <td>radboud</td>\n",
       "      <td>4</td>\n",
       "      <td>3+5</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10623</th>\n",
       "      <td>ffcee00fd033d3ece1408035a7fd4ea7</td>\n",
       "      <td>karolinska</td>\n",
       "      <td>1</td>\n",
       "      <td>3+3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2489 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                               image_id data_provider  isup_grade  \\\n",
       "5      002a4db09dad406c85505a00fb6f6144    karolinska           0   \n",
       "6      003046e27c8ead3e3db155780dc5498e    karolinska           1   \n",
       "10     00412139e6b04d1e1cee8421f38f6e90    karolinska           0   \n",
       "13     004f6b3a66189b4e88b6a01ba19d7d31    karolinska           1   \n",
       "29     00c15b23b30a5ba061358d9641118904       radboud           5   \n",
       "...                                 ...           ...         ...   \n",
       "10596  ff339e5fa7be6af83c1b43796092398f    karolinska           4   \n",
       "10603  ff596d5292ab979e9ba7291d0743b3fb    karolinska           0   \n",
       "10618  ffc005d56a21efbd034425623f596984    karolinska           2   \n",
       "10621  ffcbb41626c9267c5c20c4804bd5639a       radboud           4   \n",
       "10623  ffcee00fd033d3ece1408035a7fd4ea7    karolinska           1   \n",
       "\n",
       "      gleason_score  split  \n",
       "5               0+0      0  \n",
       "6               3+3      0  \n",
       "10              0+0      0  \n",
       "13              3+3      0  \n",
       "29              4+5      0  \n",
       "...             ...    ...  \n",
       "10596           4+4      0  \n",
       "10603           0+0      0  \n",
       "10618           3+4      0  \n",
       "10621           3+5      0  \n",
       "10623           3+3      0  \n",
       "\n",
       "[2489 rows x 5 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7465\n"
     ]
    }
   ],
   "source": [
    "# an example: loading the skip dataframe and listing the possible reasons\n",
    "skip_df = pd.read_csv(Path(DATA_DIR) / Path('PANDA_Suspicious_Slides_15_05_2020.csv'))\n",
    "print(\"possible faulty slide reasons\", skip_df['reason'].unique())\n",
    "\n",
    "fold_df = PandasDataLoader(images_csv_path=Path(DATA_DIR) / Path('train.csv'),\n",
    "                           skip_csv=Path(DATA_DIR) / Path('PANDA_Suspicious_Slides_15_05_2020.csv'), \n",
    "                           skip_list=[])\n",
    "\n",
    "# we create a possible stratification here, the options are by isup grade, or further distilled by isup grade and data provider\n",
    "# stratified_isup_sample or stratified_isup_dp_sample, we use the former.\n",
    "\n",
    "fold_df = fold_df.stratified_isup_sample(NFOLDS, SEED)\n",
    "\n",
    "# we can create training/validation splits from the fold column\n",
    "train_df = fold_df[fold_df['split'] != TRAIN_FOLD]\n",
    "valid_df = fold_df[fold_df['split'] == TRAIN_FOLD]\n",
    "\n",
    "display(train_df)\n",
    "display(valid_df)\n",
    "print(len(train_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "********************\n",
      "Notebook info\n",
      "Training data : 7465\n",
      "Validing data : 2489\n",
      "Categorical classes : 6\n",
      "Training image size : 256\n",
      "Training epochs : 15\n",
      "********************\n"
     ]
    }
   ],
   "source": [
    "FOLDED_NUM_TRAIN_IMAGES = train_df.shape[0]\n",
    "FOLDED_NUM_VALID_IMAGES = valid_df.shape[0]\n",
    "STEPS_PER_EPOCH = FOLDED_NUM_TRAIN_IMAGES // BATCH_SIZE  # Calculate the steps for keras\n",
    "VALIDATION_STEPS = FOLDED_NUM_VALID_IMAGES // BATCH_SIZE  # Calculate the same for validation\n",
    "\n",
    "\n",
    "print('*'*20)\n",
    "print('Notebook info')\n",
    "print('Training data : {}'.format(FOLDED_NUM_TRAIN_IMAGES))\n",
    "print('Validing data : {}'.format(FOLDED_NUM_VALID_IMAGES))\n",
    "print('Categorical classes : {}'.format(NUM_CLASSES))\n",
    "print('Training image size : {}'.format(SZ))\n",
    "print('Training epochs : {}'.format(NUM_EPOCHS))\n",
    "print('*'*20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "coords = np.load('../coordinates/1-16-256-255.npy',allow_pickle=True)\n",
    "\n",
    "data = TiffFromCoords(coords = coords,\n",
    "                             df=train_df, \n",
    "                             img_dir=IMG_DIR, \n",
    "                             batch_size=BATCH_SIZE, \n",
    "                             aug_func=None,\n",
    "                             tf_aug_list = [],\n",
    "                             one_hot=False)\n",
    "\n",
    "# do not use augmentation for the val_data, if aug_func is empty (None default), then no augmentation is used.\n",
    "val_data = TiffFromCoords(coords = coords,\n",
    "                         df=valid_df, \n",
    "                         img_dir=IMG_DIR, \n",
    "                         batch_size=BATCH_SIZE, \n",
    "                         aug_func=None,\n",
    "                         one_hot=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def qwk_act(x):\n",
    "    x = K.switch(x>=0, x, 0)\n",
    "    x = K.switch(x <=5, x, 5)\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "classes weigths: {0: 1.0, 1: 1.142550911039657, 2: 2.260869565217391, 4: 2.4704519119351103, 3: 2.532066508313539, 5: 2.6031746031746033}\n"
     ]
    }
   ],
   "source": [
    "lbl_value_counts = train_df['isup_grade'].value_counts()\n",
    "class_weights = {i: max(lbl_value_counts) / v for i, v in lbl_value_counts.items()}\n",
    "print('classes weigths:', class_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from model.layers import GeneralizedMeanPooling2D\n",
    "\n",
    "bottleneck = efn.EfficientNetB1( \n",
    "    include_top=False, \n",
    "    pooling='avg',\n",
    "    weights='imagenet'\n",
    ")\n",
    "\n",
    "#ResNext50, _ = Classifiers.get('resnext50')\n",
    "#bottleneck = ResNext50(input_shape=(SZ, SZ, 3),\n",
    "#                       weights='imagenet', include_top=False)\n",
    "\n",
    "\n",
    "from tensorflow.keras import Sequential\n",
    "bottleneck = Model(inputs=bottleneck.inputs, outputs=bottleneck.layers[-2].output)\n",
    "model = Sequential()\n",
    "model.add(KL.TimeDistributed(bottleneck, input_shape=(NUM_TILES, SZ, SZ, 3)))\n",
    "model.add(KL.TimeDistributed(KL.BatchNormalization()))\n",
    "model.add(KL.TimeDistributed(KL.GlobalMaxPooling2D()))\n",
    "model.add(KL.Flatten())\n",
    "model.add(KL.BatchNormalization())\n",
    "model.add(KL.Dropout(.25))\n",
    "model.add(KL.Dense(512, activation='elu'))\n",
    "model.add(KL.BatchNormalization())\n",
    "model.add(KL.Dropout(.25))\n",
    "model.add(KL.Dense(1, activation=qwk_act, dtype='float32'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Optional, List, Union\n",
    "import datetime\n",
    "\n",
    "class Config():\n",
    "    \n",
    "    num_epochs = 1\n",
    "    num_grad_accumulates = 5\n",
    "    step_summary_output = 2\n",
    "    learning_rate = 1e-3\n",
    "    model_name = 'ni'\n",
    "    \n",
    "config = Config()\n",
    "    \n",
    "def accumulated_gradients(gradients: Optional[List[tf.Tensor]],\n",
    "                          step_gradients: List[Union[tf.Tensor, tf.IndexedSlices]],\n",
    "                          num_grad_accumulates: int) -> tf.Tensor:\n",
    "    if gradients is None:\n",
    "        gradients = [flat_gradients(g) / num_grad_accumulates for g in step_gradients]\n",
    "    else:\n",
    "        for i, g in enumerate(step_gradients):\n",
    "            gradients[i] += flat_gradients(g) / num_grad_accumulates\n",
    "        \n",
    "    return gradients\n",
    "\n",
    "# This is needed for tf.gather like operations.\n",
    "def flat_gradients(grads_or_idx_slices: tf.Tensor) -> tf.Tensor:\n",
    "    '''Convert gradients if it's tf.IndexedSlices.\n",
    "    When computing gradients for operation concerning `tf.gather`, the type of gradients \n",
    "    '''\n",
    "    if type(grads_or_idx_slices) == tf.IndexedSlices:\n",
    "        return tf.scatter_nd(\n",
    "            tf.expand_dims(grads_or_idx_slices.indices, 1),\n",
    "            grads_or_idx_slices.values,\n",
    "            grads_or_idx_slices.dense_shape\n",
    "        )\n",
    "    return grads_or_idx_slices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow_addons.metrics import CohenKappa\n",
    "\n",
    "loss_fn = tf.keras.losses.MeanSquaredError(reduction=tf.keras.losses.Reduction.NONE)\n",
    "\n",
    "\n",
    "optimizer = tf.keras.optimizers.Adam(config.learning_rate)\n",
    "train_loss = tf.keras.metrics.Mean('loss/train', dtype=tf.float32)\n",
    "train_kappa = CohenKappa(num_classes=6, \n",
    "                         regression=True, \n",
    "                         sparse_labels=True, \n",
    "                         weightage='quadratic')\n",
    "metrics = [train_loss, train_kappa]\n",
    "\n",
    "current_time = datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "train_log_dir = f'logs/{config.model_name}/{current_time}'\n",
    "train_summary_writer = tf.summary.create_file_writer(train_log_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE loss 5.0268                   kappa 0.0735                   i 4 gs 1\r"
     ]
    }
   ],
   "source": [
    "def train(config: Config,\n",
    "          dataset: tf.data.Dataset,\n",
    "          model: Model):\n",
    "    global_step = 0\n",
    "    for e in range(config.num_epochs):\n",
    "        global_step = train_epoch(config, dataset, model, global_step)\n",
    "        print(f'{e+1} epoch finished. step: {global_step}')\n",
    "\n",
    "\n",
    "def train_epoch(config: Config,\n",
    "                dataset: tf.data.Dataset,\n",
    "                model: Model,\n",
    "                start_step: int = 0) -> tf.Tensor:\n",
    "    '''Train 1 epoch\n",
    "    '''\n",
    "    gradients = None\n",
    "    global_step = start_step\n",
    "    for i, batch in enumerate(dataset):\n",
    "        dummy_step = i + start_step * config.num_grad_accumulates\n",
    "        x_train, y_train = batch\n",
    "        step_gradients = train_step(x_train, y_train, loss_fn, optimizer)\n",
    "        gradients = accumulated_gradients(gradients, step_gradients, config.num_grad_accumulates)\n",
    "        if (dummy_step + 1) % config.num_grad_accumulates == 0:\n",
    "            gradient_zip = zip(gradients, model.trainable_variables)\n",
    "            optimizer.apply_gradients(gradient_zip)\n",
    "            gradients = None\n",
    "            if (global_step + 1) % config.step_summary_output == 0:\n",
    "                pass\n",
    "                #write_train_summary(train_summary_writer, metrics, step=global_step + 1)\n",
    "            global_step += 1\n",
    "            print(f\"MSE loss {train_loss.result().numpy():.4f} \\\n",
    "                  kappa {train_kappa.result().numpy():.4f} \\\n",
    "                  i {i} gs {global_step}\",\n",
    "                  end=\"\\r\")\n",
    "    train_loss.reset_states()\n",
    "    train_kappa.reset_states()\n",
    "    return global_step\n",
    "\n",
    "\n",
    "@tf.function\n",
    "def train_step(x_train: tf.Tensor,\n",
    "               y_train: tf.Tensor,\n",
    "               loss_fn: tf.keras.losses.Loss,\n",
    "               optimizer: tf.keras.optimizers.Optimizer):\n",
    "    '''Train 1 step and return gradients\n",
    "    '''\n",
    "    with tf.GradientTape() as tape:\n",
    "        outputs = model(x_train, training=True)\n",
    "        loss = tf.reduce_mean(loss_fn(y_train, outputs))\n",
    "    train_loss(loss)\n",
    "    train_kappa(y_train, outputs)\n",
    "    gradients = tape.gradient(loss, model.trainable_variables)\n",
    "    return gradients\n",
    "\n",
    "\n",
    "train(config, data(mode='training'), model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1493"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.data.experimental.cardinality(data()).numpy()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
